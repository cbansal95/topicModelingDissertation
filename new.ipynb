{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Invalid requirement: 'numpy=1.11.0'\n",
      "Hint: = is not a valid operator. Did you mean == ?\n",
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 23.2.1\n",
      "[notice] To update, run: C:\\Users\\asusa\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "%pip install numpy==1.11.0\n",
    "# Prepare data\n",
    "trump = pd.read_csv('./tweets_01-08-2021.csv')\n",
    "trump.text = trump.apply(lambda row: re.sub(r\"http\\S+\", \"\", row.text).lower(), 1)\n",
    "trump.text = trump.apply(lambda row: \" \".join(filter(lambda x:x[0]!=\"@\", row.text.split())), 1)\n",
    "trump.text = trump.apply(lambda row: \" \".join(re.sub(\"[^a-zA-Z]+\", \" \", row.text).split()), 1)\n",
    "trump = trump.loc[(trump.isRetweet == \"f\") & (trump.text != \"\"), :]\n",
    "timestamps = trump.date.to_list()\n",
    "tweets = trump.text.to_list()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Skipping pycocotools as it is not installed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pycocotools\n",
      "  Downloading pycocotools-2.0.6.tar.gz (24 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting matplotlib>=2.1.0 (from pycocotools)\n",
      "  Downloading matplotlib-3.7.2-cp311-cp311-win_amd64.whl (7.5 MB)\n",
      "                                              0.0/7.5 MB ? eta -:--:--\n",
      "                                              0.0/7.5 MB ? eta -:--:--\n",
      "                                              0.1/7.5 MB 1.7 MB/s eta 0:00:05\n",
      "     -                                        0.2/7.5 MB 1.8 MB/s eta 0:00:05\n",
      "     -                                        0.3/7.5 MB 1.9 MB/s eta 0:00:04\n",
      "     --                                       0.4/7.5 MB 2.1 MB/s eta 0:00:04\n",
      "     --                                       0.4/7.5 MB 2.1 MB/s eta 0:00:04\n",
      "     --                                       0.6/7.5 MB 1.9 MB/s eta 0:00:04\n",
      "     ---                                      0.7/7.5 MB 2.0 MB/s eta 0:00:04\n",
      "     ---                                      0.7/7.5 MB 2.0 MB/s eta 0:00:04\n",
      "     ----                                     0.8/7.5 MB 1.9 MB/s eta 0:00:04\n",
      "     ----                                     0.9/7.5 MB 1.9 MB/s eta 0:00:04\n",
      "     ----                                     0.9/7.5 MB 1.9 MB/s eta 0:00:04\n",
      "     -----                                    1.0/7.5 MB 1.9 MB/s eta 0:00:04\n",
      "     ------                                   1.1/7.5 MB 2.0 MB/s eta 0:00:04\n",
      "     ------                                   1.3/7.5 MB 2.0 MB/s eta 0:00:04\n",
      "     -------                                  1.4/7.5 MB 2.1 MB/s eta 0:00:03\n",
      "     -------                                  1.4/7.5 MB 2.1 MB/s eta 0:00:03\n",
      "     -------                                  1.5/7.5 MB 2.0 MB/s eta 0:00:03\n",
      "     -------                                  1.5/7.5 MB 2.0 MB/s eta 0:00:03\n",
      "     --------                                 1.6/7.5 MB 1.9 MB/s eta 0:00:04\n",
      "     ---------                                1.7/7.5 MB 1.9 MB/s eta 0:00:04\n",
      "     ---------                                1.7/7.5 MB 1.9 MB/s eta 0:00:04\n",
      "     ---------                                1.8/7.5 MB 1.8 MB/s eta 0:00:04\n",
      "     ---------                                1.8/7.5 MB 1.8 MB/s eta 0:00:04\n",
      "     ---------                                1.8/7.5 MB 1.8 MB/s eta 0:00:04\n",
      "     ----------                               1.9/7.5 MB 1.8 MB/s eta 0:00:04\n",
      "     ----------                               2.0/7.5 MB 1.7 MB/s eta 0:00:04\n",
      "     ----------                               2.0/7.5 MB 1.7 MB/s eta 0:00:04\n",
      "     ----------                               2.1/7.5 MB 1.7 MB/s eta 0:00:04\n",
      "     -----------                              2.1/7.5 MB 1.7 MB/s eta 0:00:04\n",
      "     -----------                              2.2/7.5 MB 1.7 MB/s eta 0:00:04\n",
      "     ------------                             2.3/7.5 MB 1.7 MB/s eta 0:00:04\n",
      "     ------------                             2.3/7.5 MB 1.7 MB/s eta 0:00:04\n",
      "     ------------                             2.4/7.5 MB 1.7 MB/s eta 0:00:04\n",
      "     ------------                             2.4/7.5 MB 1.7 MB/s eta 0:00:04\n",
      "     -------------                            2.5/7.5 MB 1.6 MB/s eta 0:00:04\n",
      "     --------------                           2.7/7.5 MB 1.7 MB/s eta 0:00:03\n",
      "     ---------------                          2.9/7.5 MB 1.8 MB/s eta 0:00:03\n",
      "     ----------------                         3.2/7.5 MB 1.9 MB/s eta 0:00:03\n",
      "     ------------------                       3.5/7.5 MB 2.0 MB/s eta 0:00:03\n",
      "     -------------------                      3.7/7.5 MB 2.1 MB/s eta 0:00:02\n",
      "     ---------------------                    4.0/7.5 MB 2.2 MB/s eta 0:00:02\n",
      "     -----------------------                  4.3/7.5 MB 2.3 MB/s eta 0:00:02\n",
      "     ------------------------                 4.6/7.5 MB 2.4 MB/s eta 0:00:02\n",
      "     --------------------------               4.9/7.5 MB 2.5 MB/s eta 0:00:02\n",
      "     ---------------------------              5.2/7.5 MB 2.6 MB/s eta 0:00:01\n",
      "     -----------------------------            5.5/7.5 MB 2.7 MB/s eta 0:00:01\n",
      "     -------------------------------          5.8/7.5 MB 2.8 MB/s eta 0:00:01\n",
      "     --------------------------------         6.1/7.5 MB 2.9 MB/s eta 0:00:01\n",
      "     ----------------------------------       6.5/7.5 MB 3.0 MB/s eta 0:00:01\n",
      "     ------------------------------------     6.8/7.5 MB 3.1 MB/s eta 0:00:01\n",
      "     --------------------------------------   7.2/7.5 MB 3.2 MB/s eta 0:00:01\n",
      "     ---------------------------------------  7.5/7.5 MB 3.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 7.5/7.5 MB 3.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy in c:\\users\\asusa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pycocotools) (1.24.3)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib>=2.1.0->pycocotools)\n",
      "  Downloading contourpy-1.1.0-cp311-cp311-win_amd64.whl (470 kB)\n",
      "                                              0.0/470.9 kB ? eta -:--:--\n",
      "     -------------------------------        389.1/470.9 kB 8.1 MB/s eta 0:00:01\n",
      "     -------------------------------------- 470.9/470.9 kB 7.4 MB/s eta 0:00:00\n",
      "Collecting cycler>=0.10 (from matplotlib>=2.1.0->pycocotools)\n",
      "  Downloading cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib>=2.1.0->pycocotools)\n",
      "  Downloading fonttools-4.41.1-cp311-cp311-win_amd64.whl (2.1 MB)\n",
      "                                              0.0/2.1 MB ? eta -:--:--\n",
      "     -----                                    0.3/2.1 MB 9.6 MB/s eta 0:00:01\n",
      "     ------------                             0.7/2.1 MB 8.5 MB/s eta 0:00:01\n",
      "     ------------------                       1.0/2.1 MB 8.8 MB/s eta 0:00:01\n",
      "     ------------------------                 1.3/2.1 MB 9.0 MB/s eta 0:00:01\n",
      "     -------------------------------          1.7/2.1 MB 8.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.1/2.1 MB 8.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 2.1/2.1 MB 8.4 MB/s eta 0:00:00\n",
      "Collecting kiwisolver>=1.0.1 (from matplotlib>=2.1.0->pycocotools)\n",
      "  Downloading kiwisolver-1.4.4-cp311-cp311-win_amd64.whl (55 kB)\n",
      "                                              0.0/55.4 kB ? eta -:--:--\n",
      "     ---------------------------------------- 55.4/55.4 kB ? eta 0:00:00\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\asusa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib>=2.1.0->pycocotools) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\asusa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib>=2.1.0->pycocotools) (10.0.0)\n",
      "Collecting pyparsing<3.1,>=2.3.1 (from matplotlib>=2.1.0->pycocotools)\n",
      "  Downloading pyparsing-3.0.9-py3-none-any.whl (98 kB)\n",
      "                                              0.0/98.3 kB ? eta -:--:--\n",
      "     ---------------------------------------- 98.3/98.3 kB ? eta 0:00:00\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\asusa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib>=2.1.0->pycocotools) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\asusa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from python-dateutil>=2.7->matplotlib>=2.1.0->pycocotools) (1.16.0)\n",
      "Building wheels for collected packages: pycocotools\n",
      "  Building wheel for pycocotools (pyproject.toml): started\n",
      "  Building wheel for pycocotools (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for pycocotools: filename=pycocotools-2.0.6-cp311-cp311-win_amd64.whl size=85214 sha256=cab15d40a1faa008988d3459495d3a044f1f7f0b26b58d66d1bea5abe8af2a01\n",
      "  Stored in directory: c:\\users\\asusa\\appdata\\local\\pip\\cache\\wheels\\ad\\ca\\ea\\fb115e04c841c3f71fd369b7d9805a43a5193f4f9251bed0ec\n",
      "Successfully built pycocotools\n",
      "Installing collected packages: pyparsing, kiwisolver, fonttools, cycler, contourpy, matplotlib, pycocotools\n",
      "Successfully installed contourpy-1.1.0 cycler-0.11.0 fonttools-4.41.1 kiwisolver-1.4.4 matplotlib-3.7.2 pycocotools-2.0.6 pyparsing-3.0.9\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 23.2.1\n",
      "[notice] To update, run: C:\\Users\\asusa\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n",
      "Batches: 100%|██████████| 32/32 [00:07<00:00,  4.12it/s]\n",
      "2023-07-31 22:59:13,435 - BERTopic - Transformed documents to Embeddings\n",
      "2023-07-31 22:59:16,363 - BERTopic - Reduced dimensionality\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'numpy.float64' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\bertopic\\_bertopic.py:3218\u001b[0m, in \u001b[0;36mBERTopic._cluster_embeddings\u001b[1;34m(self, umap_embeddings, documents, partial_fit, y)\u001b[0m\n\u001b[0;32m   3217\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3218\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhdbscan_model\u001b[39m.\u001b[39;49mfit(umap_embeddings, y\u001b[39m=\u001b[39;49my)\n\u001b[0;32m   3219\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\hdbscan\\hdbscan_.py:1205\u001b[0m, in \u001b[0;36mHDBSCAN.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m   1196\u001b[0m kwargs\u001b[39m.\u001b[39mupdate(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_metric_kwargs)\n\u001b[0;32m   1198\u001b[0m (\n\u001b[0;32m   1199\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlabels_,\n\u001b[0;32m   1200\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprobabilities_,\n\u001b[0;32m   1201\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcluster_persistence_,\n\u001b[0;32m   1202\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_condensed_tree,\n\u001b[0;32m   1203\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_single_linkage_tree,\n\u001b[0;32m   1204\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_min_spanning_tree,\n\u001b[1;32m-> 1205\u001b[0m ) \u001b[39m=\u001b[39m hdbscan(clean_data, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1207\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmetric \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mprecomputed\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_all_finite:\n\u001b[0;32m   1208\u001b[0m     \u001b[39m# remap indices to align with original data in the case of non-finite entries.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\hdbscan\\hdbscan_.py:884\u001b[0m, in \u001b[0;36mhdbscan\u001b[1;34m(X, min_cluster_size, min_samples, alpha, cluster_selection_epsilon, max_cluster_size, metric, p, leaf_size, algorithm, memory, approx_min_span_tree, gen_min_span_tree, core_dist_n_jobs, cluster_selection_method, allow_single_cluster, match_reference_implementation, **kwargs)\u001b[0m\n\u001b[0;32m    868\u001b[0m             (single_linkage_tree, result_min_span_tree) \u001b[39m=\u001b[39m memory\u001b[39m.\u001b[39mcache(\n\u001b[0;32m    869\u001b[0m                 _hdbscan_boruvka_balltree\n\u001b[0;32m    870\u001b[0m             )(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    880\u001b[0m                 \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[0;32m    881\u001b[0m             )\n\u001b[0;32m    883\u001b[0m \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m--> 884\u001b[0m     _tree_to_labels(\n\u001b[0;32m    885\u001b[0m         X,\n\u001b[0;32m    886\u001b[0m         single_linkage_tree,\n\u001b[0;32m    887\u001b[0m         min_cluster_size,\n\u001b[0;32m    888\u001b[0m         cluster_selection_method,\n\u001b[0;32m    889\u001b[0m         allow_single_cluster,\n\u001b[0;32m    890\u001b[0m         match_reference_implementation,\n\u001b[0;32m    891\u001b[0m         cluster_selection_epsilon,\n\u001b[0;32m    892\u001b[0m         max_cluster_size,\n\u001b[0;32m    893\u001b[0m     )\n\u001b[0;32m    894\u001b[0m     \u001b[39m+\u001b[39m (result_min_span_tree,)\n\u001b[0;32m    895\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\hdbscan\\hdbscan_.py:78\u001b[0m, in \u001b[0;36m_tree_to_labels\u001b[1;34m(X, single_linkage_tree, min_cluster_size, cluster_selection_method, allow_single_cluster, match_reference_implementation, cluster_selection_epsilon, max_cluster_size)\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Converts a pretrained tree and cluster size into a\u001b[39;00m\n\u001b[0;32m     76\u001b[0m \u001b[39mset of labels and probabilities.\u001b[39;00m\n\u001b[0;32m     77\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m---> 78\u001b[0m condensed_tree \u001b[39m=\u001b[39m condense_tree(single_linkage_tree, min_cluster_size)\n\u001b[0;32m     79\u001b[0m stability_dict \u001b[39m=\u001b[39m compute_stability(condensed_tree)\n",
      "File \u001b[1;32mhdbscan\\\\_hdbscan_tree.pyx:43\u001b[0m, in \u001b[0;36mhdbscan._hdbscan_tree.condense_tree\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mhdbscan\\\\_hdbscan_tree.pyx:114\u001b[0m, in \u001b[0;36mhdbscan._hdbscan_tree.condense_tree\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'numpy.float64' object cannot be interpreted as an integer",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[39mdel\u001b[39;00m timestamps[\u001b[39m1000\u001b[39m:]\n\u001b[0;32m      7\u001b[0m topic_model \u001b[39m=\u001b[39m BERTopic(verbose\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m----> 8\u001b[0m topics, probs \u001b[39m=\u001b[39m topic_model\u001b[39m.\u001b[39;49mfit_transform(tweets)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\bertopic\\_bertopic.py:389\u001b[0m, in \u001b[0;36mBERTopic.fit_transform\u001b[1;34m(self, documents, embeddings, images, y)\u001b[0m\n\u001b[0;32m    386\u001b[0m umap_embeddings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reduce_dimensionality(embeddings, y)\n\u001b[0;32m    388\u001b[0m \u001b[39m# Cluster reduced embeddings\u001b[39;00m\n\u001b[1;32m--> 389\u001b[0m documents, probabilities \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_cluster_embeddings(umap_embeddings, documents, y\u001b[39m=\u001b[39;49my)\n\u001b[0;32m    391\u001b[0m \u001b[39m# Sort and Map Topic IDs by their frequency\u001b[39;00m\n\u001b[0;32m    392\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnr_topics:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\bertopic\\_bertopic.py:3220\u001b[0m, in \u001b[0;36mBERTopic._cluster_embeddings\u001b[1;34m(self, umap_embeddings, documents, partial_fit, y)\u001b[0m\n\u001b[0;32m   3218\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhdbscan_model\u001b[39m.\u001b[39mfit(umap_embeddings, y\u001b[39m=\u001b[39my)\n\u001b[0;32m   3219\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m-> 3220\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhdbscan_model\u001b[39m.\u001b[39;49mfit(umap_embeddings)\n\u001b[0;32m   3222\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   3223\u001b[0m     labels \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhdbscan_model\u001b[39m.\u001b[39mlabels_\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\hdbscan\\hdbscan_.py:1205\u001b[0m, in \u001b[0;36mHDBSCAN.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m   1195\u001b[0m kwargs\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39mprediction_data\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[0;32m   1196\u001b[0m kwargs\u001b[39m.\u001b[39mupdate(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_metric_kwargs)\n\u001b[0;32m   1198\u001b[0m (\n\u001b[0;32m   1199\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlabels_,\n\u001b[0;32m   1200\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprobabilities_,\n\u001b[0;32m   1201\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcluster_persistence_,\n\u001b[0;32m   1202\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_condensed_tree,\n\u001b[0;32m   1203\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_single_linkage_tree,\n\u001b[0;32m   1204\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_min_spanning_tree,\n\u001b[1;32m-> 1205\u001b[0m ) \u001b[39m=\u001b[39m hdbscan(clean_data, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1207\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmetric \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mprecomputed\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_all_finite:\n\u001b[0;32m   1208\u001b[0m     \u001b[39m# remap indices to align with original data in the case of non-finite entries.\u001b[39;00m\n\u001b[0;32m   1209\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_condensed_tree \u001b[39m=\u001b[39m remap_condensed_tree(\n\u001b[0;32m   1210\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_condensed_tree, internal_to_raw, outliers\n\u001b[0;32m   1211\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\hdbscan\\hdbscan_.py:884\u001b[0m, in \u001b[0;36mhdbscan\u001b[1;34m(X, min_cluster_size, min_samples, alpha, cluster_selection_epsilon, max_cluster_size, metric, p, leaf_size, algorithm, memory, approx_min_span_tree, gen_min_span_tree, core_dist_n_jobs, cluster_selection_method, allow_single_cluster, match_reference_implementation, **kwargs)\u001b[0m\n\u001b[0;32m    867\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    868\u001b[0m             (single_linkage_tree, result_min_span_tree) \u001b[39m=\u001b[39m memory\u001b[39m.\u001b[39mcache(\n\u001b[0;32m    869\u001b[0m                 _hdbscan_boruvka_balltree\n\u001b[0;32m    870\u001b[0m             )(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    880\u001b[0m                 \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[0;32m    881\u001b[0m             )\n\u001b[0;32m    883\u001b[0m \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m--> 884\u001b[0m     _tree_to_labels(\n\u001b[0;32m    885\u001b[0m         X,\n\u001b[0;32m    886\u001b[0m         single_linkage_tree,\n\u001b[0;32m    887\u001b[0m         min_cluster_size,\n\u001b[0;32m    888\u001b[0m         cluster_selection_method,\n\u001b[0;32m    889\u001b[0m         allow_single_cluster,\n\u001b[0;32m    890\u001b[0m         match_reference_implementation,\n\u001b[0;32m    891\u001b[0m         cluster_selection_epsilon,\n\u001b[0;32m    892\u001b[0m         max_cluster_size,\n\u001b[0;32m    893\u001b[0m     )\n\u001b[0;32m    894\u001b[0m     \u001b[39m+\u001b[39m (result_min_span_tree,)\n\u001b[0;32m    895\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\hdbscan\\hdbscan_.py:78\u001b[0m, in \u001b[0;36m_tree_to_labels\u001b[1;34m(X, single_linkage_tree, min_cluster_size, cluster_selection_method, allow_single_cluster, match_reference_implementation, cluster_selection_epsilon, max_cluster_size)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_tree_to_labels\u001b[39m(\n\u001b[0;32m     66\u001b[0m     X,\n\u001b[0;32m     67\u001b[0m     single_linkage_tree,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     73\u001b[0m     max_cluster_size\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m,\n\u001b[0;32m     74\u001b[0m ):\n\u001b[0;32m     75\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Converts a pretrained tree and cluster size into a\u001b[39;00m\n\u001b[0;32m     76\u001b[0m \u001b[39m    set of labels and probabilities.\u001b[39;00m\n\u001b[0;32m     77\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 78\u001b[0m     condensed_tree \u001b[39m=\u001b[39m condense_tree(single_linkage_tree, min_cluster_size)\n\u001b[0;32m     79\u001b[0m     stability_dict \u001b[39m=\u001b[39m compute_stability(condensed_tree)\n\u001b[0;32m     80\u001b[0m     labels, probabilities, stabilities \u001b[39m=\u001b[39m get_clusters(\n\u001b[0;32m     81\u001b[0m         condensed_tree,\n\u001b[0;32m     82\u001b[0m         stability_dict,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     87\u001b[0m         max_cluster_size,\n\u001b[0;32m     88\u001b[0m     )\n",
      "File \u001b[1;32mhdbscan\\\\_hdbscan_tree.pyx:43\u001b[0m, in \u001b[0;36mhdbscan._hdbscan_tree.condense_tree\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mhdbscan\\\\_hdbscan_tree.pyx:114\u001b[0m, in \u001b[0;36mhdbscan._hdbscan_tree.condense_tree\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'numpy.float64' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "from bertopic import BERTopic\n",
    "del tweets[1000:]\n",
    "del timestamps[1000:]\n",
    "\n",
    "topic_model = BERTopic(verbose=True)\n",
    "topics, probs = topic_model.fit_transform(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "This BERTopic instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m topic_model\u001b[39m.\u001b[39;49mget_topic_info()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\bertopic\\_bertopic.py:1464\u001b[0m, in \u001b[0;36mBERTopic.get_topic_info\u001b[1;34m(self, topic)\u001b[0m\n\u001b[0;32m   1449\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_topic_info\u001b[39m(\u001b[39mself\u001b[39m, topic: \u001b[39mint\u001b[39m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m pd\u001b[39m.\u001b[39mDataFrame:\n\u001b[0;32m   1450\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\" Get information about each topic including its ID, frequency, and name.\u001b[39;00m\n\u001b[0;32m   1451\u001b[0m \n\u001b[0;32m   1452\u001b[0m \u001b[39m    Arguments:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1462\u001b[0m \u001b[39m    ```\u001b[39;00m\n\u001b[0;32m   1463\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1464\u001b[0m     check_is_fitted(\u001b[39mself\u001b[39;49m)\n\u001b[0;32m   1466\u001b[0m     info \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtopic_sizes_\u001b[39m.\u001b[39mitems(), columns\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mTopic\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mCount\u001b[39m\u001b[39m\"\u001b[39m])\u001b[39m.\u001b[39msort_values(\u001b[39m\"\u001b[39m\u001b[39mTopic\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   1467\u001b[0m     info[\u001b[39m\"\u001b[39m\u001b[39mName\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m info\u001b[39m.\u001b[39mTopic\u001b[39m.\u001b[39mmap(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtopic_labels_)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\bertopic\\_utils.py:71\u001b[0m, in \u001b[0;36mcheck_is_fitted\u001b[1;34m(topic_model)\u001b[0m\n\u001b[0;32m     67\u001b[0m msg \u001b[39m=\u001b[39m (\u001b[39m\"\u001b[39m\u001b[39mThis \u001b[39m\u001b[39m%(name)s\u001b[39;00m\u001b[39m instance is not fitted yet. Call \u001b[39m\u001b[39m'\u001b[39m\u001b[39mfit\u001b[39m\u001b[39m'\u001b[39m\u001b[39m with \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     68\u001b[0m        \u001b[39m\"\u001b[39m\u001b[39mappropriate arguments before using this estimator.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     70\u001b[0m \u001b[39mif\u001b[39;00m topic_model\u001b[39m.\u001b[39mtopics_ \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m---> 71\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg \u001b[39m%\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mname\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mtype\u001b[39m(topic_model)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m})\n",
      "\u001b[1;31mValueError\u001b[0m: This BERTopic instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."
     ]
    }
   ],
   "source": [
    "topic_model.get_topic_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.visualize_topics()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
